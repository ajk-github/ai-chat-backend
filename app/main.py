from fastapi import FastAPI, UploadFile, File, Form, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, field_validator
from typing import Dict, Any, Optional, List
from uuid import uuid4, UUID
import os
import tempfile
import logging
from dotenv import load_dotenv
import asyncio
import atexit
import signal

# Rate limiting
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

load_dotenv()

# ===== RATE LIMITING CONFIGURATION =====
# Easy to configure - change these values to adjust rate limits
#
# Note: Upload endpoint uses IP-based rate limiting (form data extraction is complex)
# Chat and Delete endpoints use user_id-based rate limiting
#
# ABSOLUTE MAXIMUM LIMITS (based on e2-standard-2: 2 vCPUs, 8GB RAM, 20 users max):
# - Upload: 30/hour per IP (20-30 sec processing time, 10 concurrent max)
# - Chat: 300/hour, 5000/day per user (2-5 sec processing, 30 concurrent max)
# - Delete: 100/hour per user (1-2 sec processing, 10 concurrent max)

RATE_LIMITS = {
    # Upload endpoint limits (per IP address - see note above)
    "upload_per_hour": "30/hour",          # Maximum 30 uploads per IP per hour (absolute max)
    "upload_burst": "10/minute",           # Maximum 10 uploads per IP per minute (burst protection)
    
    # Chat endpoint limits (per user_id)
    "chat_per_hour": "300/hour",           # Maximum 300 chat requests per user per hour (absolute max)
    "chat_per_day": "5000/day",            # Maximum 5000 chat requests per user per day (absolute max)
    "chat_burst": "30/minute",              # Maximum 30 requests per user per minute (burst protection)
    
    # Delete endpoint limits (per user_id)
    "delete_per_hour": "100/hour",         # Maximum 100 deletions per user per hour (absolute max)
    "delete_burst": "20/minute",            # Maximum 20 deletions per user per minute (burst protection)
    
    # Global concurrent limits (all users combined)
    # Note: These are not enforced by slowapi but documented for reference
    "global_upload_concurrent": 10,        # Maximum 10 concurrent uploads globally
    "global_chat_concurrent": 30,          # Maximum 30 concurrent chat requests globally
    "global_delete_concurrent": 10,        # Maximum 10 concurrent deletions globally
}

# ===== END RATE LIMITING CONFIGURATION =====

# Reuse existing modules from src/
from pathlib import Path
import sys

ROOT_DIR = Path(__file__).resolve().parents[1]
SRC_DIR = ROOT_DIR / "src"
if str(SRC_DIR) not in sys.path:
    sys.path.insert(0, str(SRC_DIR))

from data_processing.chat_data_manager import ChatDataManager
from agents.data_query_agent import DataQueryAgent
from data_processing.mysql_catalog import MySQLCatalog
from agents.database_query_agent import DatabaseQueryAgent
from .firebase_service import FirebaseService


def sanitize_user_id(user_id: str) -> str:
    """
    Sanitize user_id to prevent path traversal attacks.
    
    Args:
        user_id: User ID from request
        
    Returns:
        Sanitized user_id
        
    Raises:
        HTTPException: If user_id contains invalid characters
    """
    # Remove any path traversal attempts
    if '..' in user_id or '/' in user_id or '\\' in user_id:
        raise HTTPException(
            status_code=400, 
            detail="Invalid user_id: path traversal characters not allowed"
        )
    
    # Remove any null bytes
    user_id = user_id.replace('\x00', '')
    
    # Basic validation - allow alphanumeric, hyphens, underscores, dots
    if not user_id or len(user_id) > 128:
        raise HTTPException(
            status_code=400,
            detail="Invalid user_id: must be 1-128 characters"
        )
    
    # Allow reasonable characters (alphanumeric, hyphens, underscores, dots)
    if not all(c.isalnum() or c in '-_.' for c in user_id):
        raise HTTPException(
            status_code=400,
            detail="Invalid user_id: contains invalid characters"
        )
    
    return user_id


def sanitize_chat_id(chat_id: str) -> str:
    """
    Sanitize and validate chat_id to prevent path traversal attacks.
    
    Chat IDs should be valid UUIDs (as generated by uuid4()).
    
    Args:
        chat_id: Chat ID from request
        
    Returns:
        Sanitized chat_id
        
    Raises:
        HTTPException: If chat_id is not a valid UUID format
    """
    if not chat_id:
        raise HTTPException(
            status_code=400,
            detail="Invalid chat_id: cannot be empty"
        )
    
    # Remove any whitespace
    chat_id = chat_id.strip()
    
    # Remove any path traversal attempts
    if '..' in chat_id or '/' in chat_id or '\\' in chat_id:
        raise HTTPException(
            status_code=400,
            detail="Invalid chat_id: path traversal characters not allowed"
        )
    
    # Remove any null bytes
    chat_id = chat_id.replace('\x00', '')
    
    # Validate UUID format (chat_ids are generated as UUIDs)
    try:
        # Try to parse as UUID to validate format
        UUID(chat_id)
    except (ValueError, TypeError):
        raise HTTPException(
            status_code=400,
            detail="Invalid chat_id: must be a valid UUID format"
        )
    
    # Additional length check (UUIDs are 36 characters with hyphens)
    if len(chat_id) > 36:
        raise HTTPException(
            status_code=400,
            detail="Invalid chat_id: exceeds maximum length"
        )
    
    return chat_id


class ChatRequest(BaseModel):
    chat_id: str
    message: str
    user_id: str
    
    @field_validator('chat_id')
    @classmethod
    def validate_chat_id(cls, v: str) -> str:
        """Validate chat_id is a valid UUID format."""
        return sanitize_chat_id(v)


class DatabaseChatRequest(BaseModel):
    """Request model for database chat endpoint."""
    message: str
    user_id: str
    chat_history: Optional[List[Dict[str, str]]] = None


async def verify_chat_ownership(chat_id: str, user_id: str) -> bool:
    """
    Verify that chat_id belongs to user_id by checking Firebase.
    
    Args:
        chat_id: Chat session ID
        user_id: User ID to verify
        
    Returns:
        True if chat belongs to user, False otherwise
    """
    try:
        fb = FirebaseService()
        chat = await asyncio.to_thread(fb.get_chat, chat_id)
        
        if not chat:
            return False
            
        chat_user_id = chat.get('userId')
        if chat_user_id and chat_user_id == user_id:
            return True
            
        return False
    except Exception as e:
        logger = logging.getLogger(__name__)
        logger.error(f"Error verifying chat ownership for chat {chat_id}, user {user_id}: {e}")
        return False


def get_user_base_dir(user_id: str) -> str:
    # Writes to data/<user_id>/
    # user_id should already be sanitized before calling this
    return str(Path("data") / user_id)


def get_processed_dir(user_id: str, chat_id: str) -> str:
    return str(Path(get_user_base_dir(user_id)) / chat_id / "processed")


app = FastAPI(title="AI AR Backend", version="1.0.0")

# Initialize rate limiter with user_id-based key function
def get_user_id_for_rate_limit(request: Request) -> str:
    """
    Extract user_id from request for rate limiting.
    Tries to extract user_id from query params first, then checks request state.
    Falls back to IP address if user_id is not available.
    
    Note: For form data and JSON body endpoints, user_id is extracted
    in middleware and stored in request.state before rate limiting.
    """
    # Try query parameter first (for /api/chat/delete)
    if "user_id" in request.query_params:
        return str(request.query_params.get("user_id"))
    
    # Check if user_id was stored in request state (set by middleware)
    if hasattr(request.state, "user_id") and request.state.user_id:
        return str(request.state.user_id)
    
    # Fall back to IP address
    return get_remote_address(request)

limiter = Limiter(key_func=get_user_id_for_rate_limit, default_limits=["1000/hour"])

# Register rate limit error handler
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

# Middleware to extract user_id from JSON body for rate limiting
@app.middleware("http")
async def extract_user_id_middleware(request: Request, call_next):
    """
    Extract user_id from JSON request body and store in request.state for rate limiting.
    This allows rate limiting to work per-user instead of per-IP.
    """
    # Extract user_id from JSON body (for /api/chat)
    if request.method == "POST" and "application/json" in request.headers.get("content-type", ""):
        try:
            # Read body without consuming it permanently
            body_bytes = await request.body()
            if body_bytes:
                import json
                body = json.loads(body_bytes)
                if "user_id" in body:
                    request.state.user_id = str(body.get("user_id"))
                # Recreate request stream for FastAPI to parse
                async def receive():
                    return {"type": "http.request", "body": body_bytes}
                request._receive = receive
        except Exception:
            pass
    
    response = await call_next(request)
    return response

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


@app.post("/api/upload")
@limiter.limit(RATE_LIMITS["upload_per_hour"])
@limiter.limit(RATE_LIMITS["upload_burst"])
async def upload_file(
    request: Request,
    file: UploadFile = File(...),
    user_id: str = Form(...),
) -> Dict[str, Any]:
    # Note: Rate limiting for upload endpoint uses IP address as fallback
    # (form data extraction in middleware is complex, so we use IP-based limiting)
    # This is acceptable since uploads are already heavily rate-limited (5/hour)
    # Sanitize user_id to prevent path traversal
    user_id = sanitize_user_id(user_id)
    
    # Create per-user base dir and chat id
    chat_id = str(uuid4())
    base_data_dir = get_user_base_dir(user_id)

    manager = ChatDataManager(base_data_dir=base_data_dir)
    tmp_path = None

    try:
        # Persist incoming file temporarily with streaming to avoid memory issues
        # This is critical for large files (50-100MB) to prevent OOM errors
        suffix = os.path.splitext(file.filename or "")[1] or ""
        tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        tmp_path = tmp_file.name
        
        try:
            # Stream file directly to disk in chunks (8KB chunks)
            # This avoids loading entire file into memory, which is critical for 50-100MB files
            chunk_size = 8192  # 8KB chunks
            total_bytes = 0
            
            while True:
                chunk = await file.read(chunk_size)
                if not chunk:
                    break
                tmp_file.write(chunk)
                total_bytes += len(chunk)
            
            tmp_file.flush()
            logging.getLogger(__name__).debug(f"Streamed {total_bytes / 1024 / 1024:.2f}MB to {tmp_path}")
        finally:
            tmp_file.close()

        # Ensure chat workspace exists
        manager.create_chat_workspace(chat_id)

        # Process file into per-chat processed/ and register in DuckDB
        result = await asyncio.to_thread(
            manager.process_uploaded_file,
            chat_id,
            tmp_path,
            file.filename or "uploaded_file",
        )

        # Build metadata from catalog tables
        tables = manager.list_chat_tables(chat_id)
        # Pick first table for the simple metadata fields expected by FE
        first = tables[0] if tables else {"columns": [], "row_count": 0, "column_count": 0}

        summary = f"Processed {len(tables)} table(s), total rows ~ {result.get('total_rows', 0)}"

        # Write chat metadata to Firestore under users/{userId}/chats/{chatId}
        try:
            await asyncio.to_thread(
                FirebaseService().create_chat_session,
                chat_id,
                user_id,
                (file.filename or "Uploaded file"),
                summary,
            )
        except Exception as fb_err:
            # Log clearly so we can diagnose
            logging.getLogger(__name__).error(f"Firebase write failed for chat {chat_id} (user {user_id}): {fb_err}")

        return {
            "chatId": chat_id,
            "summary": summary,
            "metadata": {
                "row_count": first.get("row_count", 0),
                "column_count": first.get("column_count", 0),
                "columns": first.get("columns", []),
            },
        }
    except Exception as e:
        logging.getLogger(__name__).error(f"Error processing file upload: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to process file upload")
    finally:
        # Cleanup temporary file with proper error handling
        if tmp_path:
            try:
                if os.path.exists(tmp_path):
                    os.remove(tmp_path)
                    logging.getLogger(__name__).debug(f"Cleaned up temporary file: {tmp_path}")
            except Exception as cleanup_err:
                # Log cleanup failures but don't fail the request
                logging.getLogger(__name__).warning(
                    f"Failed to cleanup temporary file {tmp_path}: {cleanup_err}"
                )
        
        # Cleanup manager resources (close any cached catalogs for this request)
        try:
            manager.close_all_catalogs()
        except Exception as cleanup_err:
            logging.getLogger(__name__).warning(f"Error cleaning up manager resources: {cleanup_err}")


@app.post("/api/chat")
@limiter.limit(RATE_LIMITS["chat_per_hour"])
@limiter.limit(RATE_LIMITS["chat_per_day"])
@limiter.limit(RATE_LIMITS["chat_burst"])
async def chat(request: Request, req: ChatRequest) -> Dict[str, Any]:
    # Sanitize user_id to prevent path traversal
    # chat_id is already validated by Pydantic validator
    user_id = sanitize_user_id(req.user_id)
    
    # Verify chat ownership
    if not await verify_chat_ownership(req.chat_id, user_id):
        raise HTTPException(
            status_code=403,
            detail="Access denied: Chat does not belong to user"
        )
    
    base_data_dir = get_user_base_dir(user_id)
    manager = ChatDataManager(base_data_dir=base_data_dir)

    try:
        # First, persist the user's message to Firestore before processing
        try:
            fb = FirebaseService()
            await asyncio.to_thread(
                fb.add_message,
                req.chat_id,
                user_id,
                'user',
                req.message,
            )
        except Exception as fb_err:
            logging.getLogger(__name__).error(f"Firebase user message write failed for chat {req.chat_id}: {fb_err}")

        catalog = manager.get_chat_catalog(req.chat_id)
        processed_dir = get_processed_dir(user_id, req.chat_id)
        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            raise HTTPException(status_code=500, detail="OPENAI_API_KEY not configured")

        agent = DataQueryAgent(
            duckdb_catalog=catalog,
            openai_api_key=openai_api_key,
            schema_profiles_dir=processed_dir,
        )

        result = await asyncio.to_thread(agent.ask, req.message, [])

        # Persist assistant response to Firestore
        try:
            fb = FirebaseService()
            await asyncio.to_thread(
                fb.add_message,
                req.chat_id,
                user_id,
                'assistant',
                result.get("answer", ""),
            )
        except Exception as fb_err:
            logging.getLogger(__name__).error(f"Firebase message write failed for chat {req.chat_id}: {fb_err}")

        return {
            "response": result.get("answer", ""),
            "messageId": str(uuid4()),
        }
    except HTTPException:
        raise
    except Exception as e:
        logging.getLogger(__name__).error(f"Error processing chat request: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Failed to process chat request")
    finally:
        # Cleanup manager resources (close any cached catalogs for this request)
        # Note: Catalog will be recreated on next request if needed (cache will handle it)
        try:
            manager.close_all_catalogs()
        except Exception as cleanup_err:
            logging.getLogger(__name__).warning(f"Error cleaning up manager resources: {cleanup_err}")


@app.delete("/api/chat/delete/{chat_id}")
@limiter.limit(RATE_LIMITS["delete_per_hour"])
@limiter.limit(RATE_LIMITS["delete_burst"])
async def delete_chat(
    request: Request,
    chat_id: str,
    user_id: str
) -> Dict[str, Any]:
    """
    Delete a chat session and all its data.
    
    Deletes:
    - Local data folder: data/{user_id}/{chat_id}/
    - Firebase document: chatSessions/{chat_id} and all messages subcollection
    """
    # Sanitize user_id and chat_id to prevent path traversal
    user_id = sanitize_user_id(user_id)
    chat_id = sanitize_chat_id(chat_id)
    
    # Verify chat ownership before deletion
    if not await verify_chat_ownership(chat_id, user_id):
        raise HTTPException(
            status_code=403,
            detail="Access denied: Chat does not belong to user"
        )
    
    base_data_dir = get_user_base_dir(user_id)
    manager = ChatDataManager(base_data_dir=base_data_dir)
    
    try:
        errors = []
        
        # Delete local data folder
        try:
            success = await asyncio.to_thread(manager.delete_chat_data, chat_id)
            if not success:
                errors.append(f"Chat data folder not found or could not be deleted")
            else:
                logging.getLogger(__name__).info(f"Deleted local data for chat {chat_id}")
        except Exception as e:
            errors.append(f"Error deleting chat data: {str(e)}")
            logging.getLogger(__name__).error(f"Failed to delete chat data for {chat_id}: {e}")
        
        # Delete Firebase data
        try:
            await asyncio.to_thread(
                FirebaseService().delete_chat,
                chat_id,
                user_id
            )
            logging.getLogger(__name__).info(f"Deleted Firebase data for chat {chat_id}")
        except Exception as fb_err:
            errors.append(f"Error deleting Firebase data: {str(fb_err)}")
            logging.getLogger(__name__).error(f"Failed to delete Firebase chat {chat_id}: {fb_err}")
        
        if errors:
            raise HTTPException(
                status_code=500,
                detail=f"Some errors occurred during deletion: {'; '.join(errors)}"
            )
        
        return {
            "success": True,
            "message": f"Chat {chat_id} deleted successfully",
            "chat_id": chat_id
        }
    finally:
        # Cleanup manager resources
        try:
            manager.close_all_catalogs()
        except Exception as cleanup_err:
            logging.getLogger(__name__).warning(f"Error cleaning up manager resources: {cleanup_err}")


# Global MySQL catalog instance (singleton)
_mysql_catalog: Optional[MySQLCatalog] = None


def get_mysql_catalog() -> MySQLCatalog:
    """
    Get or create the global MySQL catalog instance.
    
    Returns:
        MySQLCatalog instance
    """
    global _mysql_catalog
    
    if _mysql_catalog is None:
        # Get database credentials from environment (REQUIRED - no defaults for security)
        db_host = os.getenv("MYSQL_HOST")
        db_user = os.getenv("MYSQL_USER")
        db_password = os.getenv("MYSQL_PASSWORD")
        db_name = os.getenv("MYSQL_DATABASE")
        db_port = int(os.getenv("MYSQL_PORT", "3306"))  # Port can have default
        
        # Validate required credentials
        if not all([db_host, db_user, db_password, db_name]):
            missing = [k for k, v in {
                "MYSQL_HOST": db_host,
                "MYSQL_USER": db_user,
                "MYSQL_PASSWORD": db_password,
                "MYSQL_DATABASE": db_name
            }.items() if not v]
            raise ValueError(
                f"Missing required MySQL environment variables: {', '.join(missing)}. "
                "Please set them in your .env file or environment."
            )
        
        _mysql_catalog = MySQLCatalog(
            host=db_host,
            user=db_user,
            password=db_password,
            database=db_name,
            port=db_port,
            pool_size=5,
            max_overflow=10,
        )
        logging.getLogger(__name__).info(f"MySQL catalog initialized for {db_host}/{db_name}")
    
    return _mysql_catalog


@app.post("/api/db/chat")
@limiter.limit(RATE_LIMITS["chat_per_hour"])
@limiter.limit(RATE_LIMITS["chat_per_day"])
@limiter.limit(RATE_LIMITS["chat_burst"])
async def db_chat(request: Request, req: DatabaseChatRequest) -> Dict[str, Any]:
    """
    Chat endpoint for database queries (MySQL).
    
    This endpoint allows users to ask natural language questions about the database,
    which are converted to SQL queries and executed against the MySQL database.
    """
    # Sanitize user_id
    user_id = sanitize_user_id(req.user_id)
    
    try:
        # Get MySQL catalog
        catalog = get_mysql_catalog()
        
        # Get OpenAI API key
        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            raise HTTPException(status_code=500, detail="OPENAI_API_KEY not configured")
        
        # Create database query agent
        agent = DatabaseQueryAgent(
            mysql_catalog=catalog,
            openai_api_key=openai_api_key,
        )
        
        # Process the question
        result = await agent.ask(
            req.message,
            req.chat_history or []
        )
        
        return {
            "response": result.get("answer", ""),
            "sql_query": result.get("sql_query"),
            "metadata": result.get("metadata", {}),
            "success": result.get("success", False),
        }
        
    except HTTPException:
        raise
    except Exception as e:
        error_msg = str(e)
        logging.getLogger(__name__).error(f"Error processing database chat request: {e}", exc_info=True)
        # Return more detailed error in development (you can remove this in production)
        import traceback
        if os.getenv("DEBUG", "false").lower() == "true":
            raise HTTPException(
                status_code=500, 
                detail=f"Failed to process database chat request: {error_msg}\n{traceback.format_exc()}"
            )
        raise HTTPException(status_code=500, detail=f"Failed to process database chat request: {error_msg}")


@app.get("/health")
async def health() -> Dict[str, str]:
    return {"status": "ok"}


# Global cleanup function for graceful shutdown
def cleanup_on_shutdown():
    """Cleanup function called on application shutdown."""
    logger = logging.getLogger(__name__)
    logger.info("Application shutting down - performing cleanup...")
    
    # Close MySQL catalog connection pool
    global _mysql_catalog
    if _mysql_catalog:
        try:
            import asyncio
            # Try to close the pool (async operation)
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # Can't use run_until_complete in a running loop
                    logger.warning("Cannot close MySQL pool synchronously - event loop is running")
                else:
                    loop.run_until_complete(_mysql_catalog.close())
            except RuntimeError:
                # No event loop - create one
                asyncio.run(_mysql_catalog.close())
            logger.info("MySQL catalog connection pool closed")
        except Exception as e:
            logger.warning(f"Error closing MySQL catalog: {e}")
    
    # Note: Individual ChatDataManager instances are cleaned up per-request
    logger.info("Cleanup completed")


# Register cleanup handlers
atexit.register(cleanup_on_shutdown)

# Handle SIGTERM and SIGINT for graceful shutdown (Unix/Linux)
# Note: SIGTERM may not be available on Windows, but SIGINT (Ctrl+C) works
def signal_handler(signum, frame):
    """Handle shutdown signals gracefully."""
    cleanup_on_shutdown()
    import sys
    sys.exit(0)

try:
    signal.signal(signal.SIGTERM, signal_handler)
except (AttributeError, ValueError):
    # Windows doesn't support SIGTERM, but that's okay
    pass

try:
    signal.signal(signal.SIGINT, signal_handler)
except (AttributeError, ValueError):
    # If SIGINT isn't available, just use atexit
    pass


